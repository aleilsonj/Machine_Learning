modelo_rf <- randomForest(STATUS ~ .,
data = dados_treinamento,
ntree = 500,
mtry = 5,
nodesize = 1,
maxnodes = 1000)
# Fazer previsões nos dados de teste
predict_rf <- predict(modelo_rf, newdata = dados_teste)
# Calcular a acurácia
acuracia_rf <- confusionMatrix(predict_rf, dados_teste$STATUS)$overall['Accuracy']
# Obter a matriz de confusão
matriz_confusaorf <- confusionMatrix(predict_rf, dados_teste$STATUS)
matriz_confusaorf
# Naive bayes
modelo_nb <- naive_bayes(VariavelResposta ~ .,
data = dados_treinamento)
# Naive bayes
library(naivebayes)
# Naive bayes
library(e1071)
modelo_nb <- naiveBayes(VariavelResposta ~ .,
data = dados_treinamento)
modelo_nb <- naiveBayes(STATUS ~ .,
data = dados_treinamento)
# Fazer previsões nos dados de teste
predict_nb <- predict(modelo_nb, newdata = dados_teste)
# Calcular a acurácia
acuracia_nb <- confusionMatrix(predict_nb, dados_teste$STATUS)$overall['Accuracy']
# Obter a matriz de confusão
matriz_confusaonb <- confusionMatrix(predict_rf, dados_teste$STATUS)
matriz_confusaonb
# Obter a matriz de confusão
matriz_confusaonb <- confusionMatrix(predict_nb, dados_teste$STATUS)
matriz_confusaonb
acuracia_nb
modelo_nb <- naiveBayes(STATUS ~ .,
data = dados_treinamento,
laplace = 1,
fL = 5,
adjust = TRUE)
# Fazer previsões nos dados de teste
predict_nb <- predict(modelo_nb, newdata = dados_teste)
# Calcular a acurácia
acuracia_nb <- confusionMatrix(predict_nb, dados_teste$STATUS)$overall['Accuracy']
# Obter a matriz de confusão
matriz_confusaonb <- confusionMatrix(predict_nb, dados_teste$STATUS)
matriz_confusaonb
modelo_rf <- train(VariavelResposta ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl)
modelo_rf <- train(STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl)
# Fazer previsões nos dados de teste
predict_rf <- predict(modelo_rf, newdata = dados_teste)
# Calcular a acurácia
acuracia_rf <- confusionMatrix(predict_rf, dados_teste$STATUS)$overall['Accuracy']
# Obter a matriz de confusão
matriz_confusaorf <- confusionMatrix(predict_rf, dados_teste$STATUS)
matriz_confusaorf
# Definir o controle do treinamento com o método "rf"
ctrl_rf <- trainControl(method = "cv", number = 5)
# Definir a grade de valores para os hiperparâmetros
tuneGrid <- expand.grid(
mtry = c(2, 4, 6),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
VariavelResposta ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = tuneGrid
)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = tuneGrid
)
# Definir a grade de valores para os hiperparâmetros
tuneGrid <- expand.grid(
mtry = c(2, 4, 5),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = tuneGrid
)
# Definir a grade de valores para os hiperparâmetros
tuneGrid <- expand.grid(
mtry = c(5),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = tuneGrid
)
# Definir a grade de valores para os hiperparâmetros
tuneGrid <- expand.grid(
mtry = c(1,2,3,4,5),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = tuneGrid
)
# Definir a grade de valores para os hiperparâmetros
tuneGrid <- expand.grid(
mtry = c(1, 2, 3, 4, 5),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 2, 3, 4 ,5)  # Número mínimo de observações em um nó final
)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = tuneGrid
)
tuneGrid <- expand.grid(
mtry = c(2, 4, 5),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Definir a grade de valores para os hiperparâmetros
asd <- expand.grid(
mtry = c(2, 4, 5),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = asd
)
# Definir a grade de valores para os hiperparâmetros
tuneGrid <- expand.grid(
mtry = c(2, 4, 5),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
View(tuneGrid)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = tuneGrid
)
# Definir a grade de valores para os hiperparâmetros
tuneGrid <- expand.grid(
mtry = c(2, 4, 5),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300, 400, 500),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Ajustar o modelo de Random Forest com os hiperparâmetros modificados
modelo_rf <- train(
STATUS ~ .,
data = dados_treinamento,
method = "rf",
trControl = ctrl_rf,
tuneGrid = tuneGrid
)
# Definir a grade de valores para os hiperparâmetros usando createGrid()
grid <- createGrid(
mtry = c(2, 4, 6),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Definir a grade de valores para os hiperparâmetros usando createGrid()
grid <- createGrid(
mtry = c(2, 4, 6),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Definir a grade de valores para os hiperparâmetros usando createGrid()
grid <- expand.grid(
mtry = c(2, 4, 6),  # Número de variáveis selecionadas aleatoriamente em cada divisão
ntree = c(100, 200, 300),  # Número de árvores na floresta
nodesize = c(1, 5, 10)  # Número mínimo de observações em um nó final
)
# Realizar busca aleatória
tuneParams <- tuneParams(
"rf",
tuneGrid = grid,
control = ctrl,
method = "random"
)
# Realizar busca aleatória
# Perform random search
tuneParams <- tuneGrid(
method = "rf",
tuneGrid = grid,
trControl = ctrl,
tuneControl = tuneControlRandom()
)
# Arquivo de controle
ctrl1 <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
# Criando Modelo KNN
knn_v2 <- train(STATUS ~ .,
data = dados_treinamento,
method = "knn",
trControl = ctrl1,
metric = "ROC",
tuneLength = 20)
# Arquivo de controle
ctrl1 <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = FALSE,
summaryFunction = twoClassSummary)
# Criando Modelo KNN
knn_v2 <- train(STATUS ~ .,
data = dados_treinamento,
method = "knn",
trControl = ctrl1,
metric = "ROC",
tuneLength = 20)
# Arquivo de controle
ctrl1 <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
# Criando Modelo KNN
knn_v2 <- train(STATUS ~ .,
data = dados_treinamento,
method = "knn",
trControl = ctrl1,
metric = "ROC",
tuneLength = 20)
dados_treinamento$SATATUS <- factor(dados_treinamento$STATUS, levels = c(0, 1), labels = c("Falha", "Sucesso"))
View(dados_treinamento)
# Criando Modelo KNN
knn_v2 <- train(STATUS ~ .,
data = dados_treinamento,
method = "knn",
trControl = ctrl1,
metric = "ROC",
tuneLength = 20)
rm(list = ls())
# Pacotes utilizados
library(readxl)
library(ggplot2)
library(reshape2)
library(dplyr)
library(e1071)
library(randomForest)
library(lattice)
library(caret)
# Carregando dataset
df <- read_xlsx("Acoustic_Extinguisher_Fire_Dataset.xlsx")
# Verificando a existência de valores NA em df
any(is.na(df)) # Não foi encontrado valores NA em df
# Verificando as classes da variáveis de df
str(df)
# Nomes das variáveis a serem convertidas
vetores <- c("SIZE", "STATUS", "FUEL")
# Loop para converter os vetores para a classe "factor"
for (vetor in vetores) {
df[[vetor]] <- as.factor(df[[vetor]])
}
# Verificando as classes da variáveis de df
str(df)
# Selecionando variáveis catégoricas
cat <- names(df)[sapply(df, is.factor) | sapply(df, is.character)]
# Selecionando numéricas
num <- names(df)[sapply(df, is.numeric)]
# ANÁLISE EXPLORATÓRIA DOS DADOS
## Desibel
hist(df$DESIBEL,
main = "Altura dos alunos do 1º ano do Ensino Médio",
xlab = "Desibel (dB)", ylab = "Freq. Absoluta",
col = c("blue"),
border = FALSE,
xlim = c(70,118), ylim = c(0,2500),
labels = TRUE)
## Histograma - AirFlow
hist(df$AIRFLOW,
main = "Fluxo de Ar durante o Experimento",
xlab = "Fluxo de Ar (m/s)", ylab = "Freq. Absoluta",
col = c("blue"),
border = FALSE,
xlim = c(0,18), ylim = c(0,2200),
labels = TRUE)
# Boxplot - Airflow
boxplot(df$AIRFLOW,
main = "Boxplot - Fluxo de Ar",
ylab = "Fluxo de Ar (m/s)",
col = "red")
summary(df$AIRFLOW)
## |Histograma - Frequency
hist(df$FREQUENCY,
main = "Frequência Durante o Experimento",
xlab = "Frequência (Hz)", ylab = "Freq. Absoluta",
col = c("blue"),
border = FALSE,
xlim = c(0,80), ylim = c(0,2000),
labels = TRUE)
# Boxplot - Frenquecy
boxplot(df$FREQUENCY,
main = "Boxplot - Frenquência",
ylab = "Frenquência (Hz)",
col = "red")
summary(df$FREQUENCY)
# Distance
hist(df$DISTANCE,
main = "Distância durante o Experimento",
xlab = "Distância (cm)", ylab = "Freq. Absoluta",
col = c("blue"),
border = FALSE,
xlim = c(0,200), ylim = c(0,2000),
labels = TRUE)
# criando tabela cruzada de frenquência entre SIZE e STATUS
tab <- table(df$SIZE, df$STATUS)
addmargins(tab)
# tabela cruzada de frenquência entre SIZE e STATUS
tab_pro <- prop.table(tab) * 100
round(tab_pro, digits = 2) # arredondando para duas casas decimais
# criando tabela cruzada de frenquência entre FUEL e STATUS
tab1 <- table(df$FUEL, df$STATUS)
tab1
# tabela cruzada de frenquência entre FUEL e STATUS
tab_pro1 <- prop.table(tab1) * 100
round(tab_pro1, digits = 2) # arredondando para duas casas decimais
# Plot - 1
plot1 <- ggplot(df, aes(x = DISTANCE, fill = STATUS)) +
geom_density(alpha = 0.5) +
labs(x = "Distância", y = "Densidade", fill = "Status") +
scale_fill_manual(values = c("red", "blue"), labels = c("Falha", "Sucesso")) +
theme_minimal() +
theme(
panel.border = element_blank(),
legend.position = "top",
legend.title = element_blank(),
legend.key.size = unit(0.5, "cm"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
plot.title = element_text(size = 14, hjust = 0.5)
) +
ggtitle("Distribuição de Sucesso e Falha por Distância")
plot1
# Plot - 2
plot2 <- ggplot(df, aes(x = AIRFLOW, fill = STATUS)) +
geom_density(alpha = 0.5) +
labs(x = "Fluxo de Ar", y = "Densidade", fill = "Status") +
scale_fill_manual(values = c("red", "blue"), labels = c("Falha", "Sucesso")) +
theme_minimal() +
theme(
panel.border = element_blank(),
legend.position = "top",
legend.title = element_blank(),
legend.key.size = unit(0.5, "cm"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
plot.title = element_text(size = 14, hjust = 0.5)
) +
ggtitle("Distribuição de Sucesso e Falha por Fluxo de Ar")
plot2
# Plot - 3
plot3 <- ggplot(df, aes(x = FREQUENCY, fill = STATUS)) +
geom_density(alpha = 0.5) +
labs(x = "Frequência (Hz)", y = "Densidade", fill = "Status") +
scale_fill_manual(values = c("red", "blue"), labels = c("Falha", "Sucesso")) +
theme_minimal() +
theme(
panel.border = element_blank(),
legend.position = "top",
legend.title = element_blank(),
legend.key.size = unit(0.5, "cm"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
plot.title = element_text(size = 14, hjust = 0.5)
) +
ggtitle("Distribuição de Sucesso e Falha por Frequência (Hz)")
plot3
# 6.
ggplot(df, aes(x = DESIBEL, fill = STATUS)) +
geom_density(alpha = 0.3) +
labs(x = "Frequência (Hz)", y = "Densidade", fill = "Status") +
scale_fill_manual(values = c("red", "blue"), labels = c("Falha", "Sucesso")) +
theme_minimal() +
theme(
panel.border = element_blank(),
legend.position = "top",
legend.title = element_blank(),
legend.key.size = unit(0.5, "cm"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
plot.title = element_text(size = 14, hjust = 0.5)
) +
ggtitle("Distribuição de Sucesso e Falha por Frequência (Hz)")
ggplot(df, aes(x = FREQUENCY, y = AIRFLOW, color = FUEL, shape = FUEL)) +
geom_point(size = 3) +
scale_size(range = c(1, 10)) +
labs(x = "Airflow", y = "Distancia", title = "Gráfico de Dispersão")
matrizcorr <- cor(df[,num])
matriz_melt <- melt(matrizcorr)
# 6.
ggplot(df, aes(x = DESIBEL, fill = STATUS)) +
geom_density(alpha = 0.3) +
labs(x = "Frequência (Hz)", y = "Densidade", fill = "Status") +
scale_fill_manual(values = c("red", "blue"), labels = c("Falha", "Sucesso")) +
theme_minimal() +
theme(
panel.border = element_blank(),
legend.position = "top",
legend.title = element_blank(),
legend.key.size = unit(0.5, "cm"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
plot.title = element_text(size = 14, hjust = 0.5)
) +
ggtitle("Distribuição de Sucesso e Falha por Frequência (Hz)")
# Calcula a matriz de correlação
matrizcorr <- cor(df[,num])
matriz_melt <- melt(matrizcorr)
# Definir cores personalizadas
colors <- c("#FFFFFF", "#FF0000")  # Branco e Vermelho
# Plotar o heatmap com texto
ggplot(matriz_melt, aes(Var2, Var1, fill = value)) +
geom_tile(color = "black") +
geom_text(aes(label = round(value, 2)), color = "black", size = 3) +
scale_fill_gradientn(colors = colors, limits = c(-1, 1), breaks = seq(-1, 1, by = 0.2)) +
labs(x = "Variável 2", y = "Variável 1", title = "Heatmap de Correlação") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12),
legend.title = element_blank(),
legend.text = element_text(size = 10),
legend.position = "right")
# Transformando a coluna em números
df$FUEL <- recode(df$FUEL,
"gasoline" = 1,
"kerosene" = 2,
"thinner" = 3,
"lpg" = 4)
# Padronização da variáveis numéricas
df[, num] <- scale(df[, num])
# variáveis importantes de acordo com o RF
modelo <- randomForest(STATUS ~ . ,
data = df,
ntree = 100, nodesize = 10,
importance = TRUE)
varImpPlot(modelo)
# dividindo dados em treino e teste
set.seed(10)
indice_treinamento <- createDataPartition(df$FUEL, p = 0.7, list = FALSE)
dados_treinamento <- df[indice_treinamento,]
dados_teste <- df[-indice_treinamento,]
# Treinar o modelo de regressão logística
modelo_glm <- train(STATUS ~ .,
data = dados_treinamento,
method = "glm",
family = "binomial")
# Fazer previsões nos dados de teste
previsoes <- predict(modelo_glm, newdata = dados_teste)
# Calcular a acurácia
acuracia <- confusionMatrix(previsoes, dados_teste$STATUS)$overall['Accuracy']
# Obter a matriz de confusão
matriz_confusao <- confusionMatrix(previsoes, dados_teste$STATUS)
matriz_confusao
# Modelo de Classificação KNN
# Arquivo de controle
ctrl <- trainControl(method = "repeatedcv", repeats = 3)
# Criando Modelo KNN
knn_v1 <- train(STATUS ~ .,
data = dados_treinamento,
method = "knn",
trControl = ctrl,
tuneLength = 20)
# Plot
plot(knn_v1)
# Fazer previsões nos dados de teste
knnpredict <- predict(knn_v1, newdata = dados_teste)
# Calcular a acurácia
knnacuracia <- confusionMatrix(knnpredict, dados_teste$STATUS)$overall['Accuracy']
# Obter a matriz de confusão
knnmatriz_confusao <- confusionMatrix(knnpredict, dados_teste$STATUS)
# Obter a matriz de confusão
knnmatriz_confusao <- confusionMatrix(knnpredict, dados_teste$STATUS)
knn_v1
knnmatriz_confusao
